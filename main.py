import streamlit as st
import pandas as pd
import time
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType
from selenium.webdriver.common.by import By

# ==========================================
# 1. ì‚¬ì´íŠ¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="ê°•ì‚¬ ë°œêµ´ë‹¨ V3", page_icon="ğŸšœ", layout="wide")
st.title("ğŸšœ í¬ëª½ & í´ë˜ìŠ¤ìœ  [ë¬´ì¡°ê±´ ìˆ˜ì§‘] ëª¨ë“œ")
st.markdown("""
**"ë§í¬ê°€ ë³´ì´ë©´ ë¬´ì¡°ê±´ ê°€ì ¸ì˜µë‹ˆë‹¤."**
í…ìŠ¤íŠ¸ê°€ ì•ˆ ì½í˜€ë„ URLì€ 100% ì €ì¥í•˜ë„ë¡ ê°œì„ í–ˆìŠµë‹ˆë‹¤.
""")

# ìˆ˜ì§‘í•  ì¹´í…Œê³ ë¦¬ ì„ íƒ
target_source = st.radio(
    "ìˆ˜ì§‘í•  ëŒ€ìƒì„ ì„ íƒí•˜ì„¸ìš”:",
    (
        "í¬ëª½ - IT/í”„ë¡œê·¸ë˜ë° (ì „ì²´)",
        "í¬ëª½ - íˆ¬ì¡/ë¶€ì—…/ì¬í…Œí¬ (ì „ì²´)",
        "í¬ëª½ - ë§ˆì¼€íŒ… (ì „ì²´)",
        "í´ë˜ìŠ¤ìœ  - ë² ìŠ¤íŠ¸ (ì „ì²´)"
    )
)

scroll_count = st.slider("ìŠ¤í¬ë¡¤ íšŸìˆ˜ (ë§ì„ìˆ˜ë¡ ë§ì´ ê°€ì ¸ì˜´)", 1, 30, 5)

# ==========================================
# 2. ë¡œë´‡ ì„¤ì •
# ==========================================
def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    return webdriver.Chrome(
        service=Service(ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install()),
        options=chrome_options
    )

# ==========================================
# 3. ìˆ˜ì§‘ ë¡œì§ (ê°œì„ ë¨)
# ==========================================
def run_crawler(driver, target, scrolls):
    # íƒ€ê²Ÿ URL ì„¤ì •
    if "í¬ëª½ - IT" in target:
        url = "https://kmong.com/category/7"
        site_name = "í¬ëª½"
    elif "í¬ëª½ - íˆ¬ì¡" in target:
        url = "https://kmong.com/category/11"
        site_name = "í¬ëª½"
    elif "í¬ëª½ - ë§ˆì¼€íŒ…" in target:
        url = "https://kmong.com/category/9"
        site_name = "í¬ëª½"
    else:
        url = "https://www.classu.co.kr/"
        site_name = "í´ë˜ìŠ¤ìœ "

    st.info(f"ğŸš€ [{target}] ì ‘ì† ì¤‘... URL: {url}")
    
    try:
        driver.get(url)
        time.sleep(3)

        # ìŠ¤í¬ë¡¤ ë‹¤ìš´
        status_box = st.empty()
        for i in range(scrolls):
            status_box.write(f"ğŸ”„ ë°ì´í„° ë¡œë”© ì¤‘... ({i+1}/{scrolls}íšŒ)")
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
        
        status_box.write("âœ… ë¡œë”© ì™„ë£Œ! ë°ì´í„° ì¤ê¸° ì‹œì‘...")

        data_list = []
        seen_urls = set()

        # ë§í¬ ì°¾ê¸° ì „ëµ
        if site_name == "í¬ëª½":
            items = driver.find_elements(By.XPATH, '//a[contains(@href, "/gig/")]')
        else:
            items = driver.find_elements(By.TAG_NAME, 'a')

        st.write(f"ğŸ” ë§í¬ {len(items)}ê°œ ë°œê²¬! ë¶„ì„ ì‹œì‘...")

        for item in items:
            try:
                link = item.get_attribute("href")
                
                # ê¸°ë³¸ í•„í„°ë§
                if not link: continue
                if site_name == "í¬ëª½" and "/gig/" not in link: continue
                if site_name == "í´ë˜ìŠ¤ìœ " and "/class/" not in link: continue
                
                # ì¤‘ë³µ ì œê±°
                if link in seen_urls: continue
                seen_urls.add(link)

                # [í•µì‹¬ ìˆ˜ì •] í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ê°•í™” (innerText ì‚¬ìš©)
                # ëˆˆì— ì•ˆ ë³´ì—¬ë„ HTML ì•ˆì— ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ê°•ì œë¡œ ê¸ì–´ì˜µë‹ˆë‹¤.
                raw_text = item.get_attribute("textContent")
                
                if raw_text:
                    text_content = raw_text.strip().replace("\n", " ")
                else:
                    text_content = "í…ìŠ¤íŠ¸ ë¡œë”© ì‹¤íŒ¨ (ë§í¬ í™•ì¸ í•„ìš”)"

                # í…ìŠ¤íŠ¸ê°€ ì—†ì–´ë„ ë¬´ì¡°ê±´ ì €ì¥!
                data_list.append({
                    "ì‚¬ì´íŠ¸": site_name,
                    "ê°•ì˜ì •ë³´(ìš”ì•½)": text_content[:100], # ë„ˆë¬´ ê¸¸ë©´ ìë¦„
                    "URL": link
                })
            except Exception as e:
                # ì—ëŸ¬ê°€ ë‚˜ë„ ë‹¤ìŒ ê±¸ë¡œ ë„˜ì–´ê°
                continue

        return pd.DataFrame(data_list)

    except Exception as e:
        st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

# ==========================================
# 4. ì‹¤í–‰ ë²„íŠ¼
# ==========================================
if st.button("ë¬´ì¡°ê±´ ê¸ì–´ì˜¤ê¸° ğŸšœ"):
    driver = get_driver()
    result_df = run_crawler(driver, target_source, scroll_count)
    driver.quit()
    
    if not result_df.empty:
        st.success(f"ğŸ‰ ì„±ê³µ! ì´ {len(result_df)}ê°œì˜ ê°•ì˜ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
        st.dataframe(result_df)
        
        csv = result_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"ê°•ì˜ë¦¬ìŠ¤íŠ¸_{target_source[:5]}.csv",
            mime="text/csv"
        )
    else:
        st.error("ì •ë§ ì´ìƒí•˜ë„¤ìš”.. ë§í¬ëŠ” ì°¾ì•˜ëŠ”ë° ë‹´ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
